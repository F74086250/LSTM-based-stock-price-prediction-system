{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:Library linking\n",
    "#basic python\n",
    "import pandas as pd  \n",
    "pd.set_option('display.max_rows', 20)    #show setting\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  #dont show the fxxking warning\n",
    "%matplotlib inline\n",
    "\n",
    "#spider\n",
    "import requests\n",
    "\n",
    "#data processing && sklearn\n",
    "from math import sqrt #for Root-MSE(RMSE)\n",
    "from sklearn.preprocessing import MinMaxScaler       #normalization\n",
    "from sklearn.metrics import mean_squared_error       #MSE loss evaluation1\n",
    "from sklearn.metrics import mean_absolute_error      #MAE loss evaluation2\n",
    "from sklearn.metrics import explained_variance_score #loss evaluation3\n",
    "from sklearn.metrics import r2_score                 #loss evaluation4\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#keras' model && LSTM algorithm\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:Data source \n",
    "url = []\n",
    "url.append(\"https://api.finmindtrade.com/api/v4/login\") #login\n",
    "url.append(\"https://api.finmindtrade.com/api/v4/data\")  #data fetch\n",
    "dataset = []\n",
    "dataset.append(\"TaiwanStockPrice\")\n",
    "dataset.append(\"TaiwanStockMarginPurchaseShortSale\")\n",
    "dataset.append(\"TaiwanStockPER\")\n",
    "dataset.append(\"TaiwanStockTotalMarginPurchaseShortSale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:Input control(for dev.)\n",
    "TRAIN = '開盤價'\n",
    "TARGET = '收盤價'\n",
    "\n",
    "corr_rate = 0.1     #correlation threshold\n",
    "step = 5            #rolling times\n",
    "shift = 10          #rolling shift\n",
    "\n",
    "show_history_dataframe = False\n",
    "show_LSTM_config = False   #(=setting summary)\n",
    "show_loss_plot = True\n",
    "\n",
    "multi = True         #False=uniVariate True=multiVariate\n",
    "unit = 100           #units-------num of neural cells\n",
    "drop_rate = 0.2      #drop--------drop some node by this rate\n",
    "times = 150          #epoch-------whole data set training times\n",
    "group_size = 64      #batch_size--selection size per expiriment\n",
    "train_record = 0     #verbose-----0=dont show, 1=show record and progress, 2=record only \n",
    "shuff = True         #shuffle-----make random\n",
    "loss_select = 1      #choose loss function\n",
    "loss_func = ['mean_absolute_error','mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:Input control(for User)\n",
    "#note:change it if u have ur own account for Finmind \n",
    "user_id = \"F74086250\"    #by default\n",
    "password = \"Aeiou95048\"  #by default\n",
    "\n",
    "symbol = \"2330\"          #stock id\n",
    "start_date = \"2016-06-04\"\n",
    "end_date = \"2021-06-03\"\n",
    "\n",
    "show_history_plot = False\n",
    "save_history_plot = False\n",
    "show_prediction = True\n",
    "save_prediction = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:function area\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def confusion_matrix_list(real,predict):\n",
    "    real_tendency=[]\n",
    "    predicted_tendency=[]\n",
    "       \n",
    "    for i in range(1,len(real)):\n",
    "        if(real[i]-real[i-1]>0):\n",
    "            real_tendency.append(1)\n",
    "        if(real[i]-real[i-1]==0):\n",
    "            real_tendency.append(2)\n",
    "        if(real[i]-real[i-1]<0):\n",
    "            real_tendency.append(0)\n",
    "    for i in range(1,len(predict)):\n",
    "        if(predict[i]-predict[i-1]>0):\n",
    "            predicted_tendency.append(1)\n",
    "        if(predict[i]-predict[i-1]==0):\n",
    "            pedicted_tendency.append(2)\n",
    "        if(predict[i]-predict[i-1]<0):\n",
    "            predicted_tendency.append(0)\n",
    "    \n",
    "    return real_tendency,predicted_tendency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1237 elements, new values have 1223 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-99d6972e2e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mShortSale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mShortSale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"TodayBalance\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Shortsale\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mMarginPurchaseMoney\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMarginPurchaseMoney\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mShortSale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mShortSale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mdata4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMarginPurchaseMoney\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mShortSale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\f74086250\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, labels, axis, inplace)\u001b[0m\n\u001b[0;32m   4013\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4014\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4015\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4017\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\f74086250\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, labels, axis, inplace)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\f74086250\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, labels, axis, inplace)\u001b[0m\n\u001b[0;32m   4013\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4014\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4015\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4017\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\f74086250\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, labels, axis, inplace)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \"\"\"\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\f74086250\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5152\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5153\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5154\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5155\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5156\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\f74086250\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\f74086250\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    227\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1237 elements, new values have 1223 elements"
     ]
    }
   ],
   "source": [
    "#Tag:login && data fetch && manage(feat. FINmind)\n",
    "#------login && get *Token\n",
    "account = {\n",
    "    \"user_id\": user_id,\n",
    "    \"password\": password,\n",
    "}\n",
    "token = requests.post(url[0], data=account).json()['token']\n",
    "\n",
    "#------Add basic stock info. && parameter\n",
    "parameter = {\n",
    "    \"dataset\": dataset[0],\n",
    "    \"data_id\": symbol,\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": \"2021-06-04\",\n",
    "    \"token\":token\n",
    "}\n",
    "#Fetch\n",
    "data = pd.DataFrame(requests.get(url[1], params=parameter).json()[\"data\"])\n",
    "\n",
    "#------Add margin && shortsale\n",
    "parameter = {\n",
    "    \"dataset\": dataset[1],\n",
    "    \"data_id\": symbol,\n",
    "    \"start_date\": start_date,\n",
    "    \"token\":token,\n",
    "}\n",
    "#Fetch\n",
    "data2 = pd.DataFrame(requests.get(url[1], params=parameter).json()[\"data\"])\n",
    "#Modify\n",
    "data2=data2[[\"MarginPurchaseTodayBalance\",\"MarginPurchaseYesterdayBalance\",\"ShortSaleTodayBalance\",\"ShortSaleYesterdayBalance\"]]\n",
    "data2[\"MarginPurchaseVariation\"]=data2[\"MarginPurchaseTodayBalance\"]-data2[\"MarginPurchaseYesterdayBalance\"]\n",
    "data2[\"ShortSaleVariation\"]=data2[\"ShortSaleTodayBalance\"]-data2[\"ShortSaleYesterdayBalance\"]\n",
    "#data2=data2.drop(len(data2)-1,axis=0)#trim the length of data \n",
    "\n",
    "#------Add PER PBR\n",
    "parameter = {\n",
    "    \"dataset\": dataset[2],\n",
    "    \"data_id\": symbol,\n",
    "    \"start_date\": start_date,\n",
    "    \"token\":token,\n",
    "}\n",
    "#Fetch\n",
    "data3 = pd.DataFrame(requests.get(url[1], params=parameter).json()['data'])\n",
    "#Modify\n",
    "data3=data3.drop([\"date\",\"stock_id\"],axis=1)\n",
    "#data3=data3.drop(len(data3)-1,axis=0)\n",
    "\n",
    "#------Add Total margin && shortsale\n",
    "parameter = {\n",
    "    \"dataset\": dataset[3],\n",
    "    \"start_date\": start_date,\n",
    "    \"token\":token,\n",
    "}\n",
    "#Fetch\n",
    "data4 = pd.DataFrame(requests.get(url[1], params=parameter).json()['data'])[[\"TodayBalance\",\"name\"]]\n",
    "#Modify\n",
    "data4=data4[~data4['name'].isin([\"MarginPurchase\"])]\n",
    "MarginPurchaseMoney=data4[data4[\"name\"]==\"MarginPurchaseMoney\"].drop(columns=\"name\")\n",
    "MarginPurchaseMoney.rename(columns={\"TodayBalance\":\"MarginPurchaseMoney\"})\n",
    "MarginPurchaseMoney=MarginPurchaseMoney[\"TodayBalance\"]/10000000\n",
    "MarginPurchaseMoney=MarginPurchaseMoney.to_frame().rename(columns={\"TodayBalance\":\"MarginPurchaseMoney\"})\n",
    "ShortSale=data4[data4[\"name\"]==\"ShortSale\"].drop(columns=\"name\")\n",
    "ShortSale=ShortSale.rename(columns={\"TodayBalance\":\"Shortsale\"})\n",
    "mod=list(range(len(data)))\n",
    "MarginPurchaseMoney=MarginPurchaseMoney.set_axis(mod)\n",
    "ShortSale=ShortSale.set_axis(mod)\n",
    "data4=MarginPurchaseMoney.join(ShortSale)\n",
    "#data4=data4.drop(len(data4)-1,axis=0)#trim the length of data \n",
    "\n",
    "#------Add TAIEX\n",
    "data5 = pd.read_csv('TAIEX.csv')\n",
    "data5=data5.iloc[::-1]\n",
    "mod=list(range(len(data)))\n",
    "data5=data5.set_axis(mod).drop([\"Date\",\"Return\",'Percent'],axis=1)\n",
    "data5.columns = ['大盤指數','漲跌點數']\n",
    "\n",
    "#------Merge all data && translation\n",
    "data=data.join(data2)\n",
    "data=data.join(data3)\n",
    "data=data.join(data4)\n",
    "data=data.join(data5)\n",
    "data.columns=[\"日期\",\"股票編號\",\"當日成交量\",\"當日成交金額\",\"開盤價\",\"最高價\",\"最低價\",\"收盤價\",\"買賣價差\",\"周轉率\",\"當日融資\",\"昨日融資\",\"當日融卷\",\"昨日融卷\",\"融資變化\",\"融券變化\",\"殖利率\",\"本益比\",\"股價淨值比\",\"大盤融資餘額(百萬)\",\"大盤融卷量\",\"大盤指數\",\"大盤漲跌\"]\n",
    "data=data.drop(\"股票編號\",axis=1)\n",
    "data.set_index([\"日期\"], inplace=True)\n",
    "data.insert(2,column=\"平均成交價\",value=(data[\"當日成交金額\"]/data[\"當日成交量\"]).tolist())\n",
    "\n",
    "if show_history_dataframe:\n",
    "    display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:data preprocessing\n",
    "#------choose correlative data\n",
    "for column in data:\n",
    "    temp = []\n",
    "    for i in range(step):\n",
    "        temp.append(data[column].rolling((i+1)*shift).corr(data[TARGET]).mean())\n",
    "    if sum(temp)/len(temp) < corr_rate:\n",
    "        data = data.drop(column,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:Univariate\n",
    "#------slice data to test && train\n",
    "if not multi:\n",
    "    test = data[data.index>'2020-06-04']\n",
    "    train = data[data.index<='2021-06-04']\n",
    "    train_set_x = train[TRAIN]\n",
    "    train_set_y = train[TARGET]\n",
    "\n",
    "#------data normalization\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))      #re-scale data to the same range(aka. normalization) \n",
    "    train_set_x= train_set_x.values.reshape(-1,1)  #reshape: -1 = auto-calculate for fitting matrix size\n",
    "    training_set_scaled_x = sc.fit_transform(train_set_x)\n",
    "    train_set_y= train_set_y.values.reshape(-1,1)\n",
    "    training_set_scaled_y = sc.fit_transform(train_set_y)\n",
    "\n",
    "#------train data re-arrange\n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(10,len(train_set_x)):\n",
    "        X_train.append(training_set_scaled_x[i-10:i, 0]) \n",
    "        y_train.append(training_set_scaled_y[i, 0]) \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train) \n",
    "    X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "#Tag:LSTM && keras model implementation\n",
    "#------model config\n",
    "    keras.backend.clear_session()\n",
    "    model = Sequential()                                               #set-up a sequential\n",
    "    model.add(LSTM(unit,return_sequences=True,input_shape=(X_train.shape[1], 1))) #add layer(lstm)\n",
    "    model.add(Dropout(drop_rate))                                                              #add layer(dropout)\n",
    "    model.add(LSTM(unit,activation='relu'))                                       #add layer(lstm)\n",
    "    model.add(Dense(units = 1))                                                          #add layer(dense)\n",
    "    model.compile(optimizer = 'adam', loss = loss_func[loss_select])     #optimized learning && loss evaluation\n",
    "    \n",
    "#------trainning\n",
    "    history = model.fit(X_train, y_train, epochs = times, batch_size = group_size,verbose = train_record, shuffle = shuff)\n",
    "\n",
    "#------make prediction\n",
    "    dataset_total = pd.concat((train[TRAIN], test[TARGET]), axis = 0)\n",
    "    inputs = dataset_total[len(dataset_total) - len(test) - 10:].values\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    inputs = sc.transform(inputs)\n",
    "    X_test = []\n",
    "    for i in range(10, len(inputs)):\n",
    "        X_test.append(inputs[i-10:i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    predicted_stock_price = model.predict(X_test)                    #make prediction\n",
    "    predicted_stock_price = sc.inverse_transform(predicted_stock_price)  #return to original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:multivariate\n",
    "if multi:\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))      #re-scale data to the same range(aka. normalization) \n",
    "    scaled = sc.fit_transform(data.values)\n",
    "\n",
    "# specify the number of lag hours\n",
    "    n_days = 10 #可再調整\n",
    "    n_features = data.shape[1]\n",
    "    reframed = series_to_supervised(scaled, n_days, 1)\n",
    "\n",
    "    vals = reframed.values\n",
    "    n_train_day = 1000\n",
    "    train = vals[:n_train_day, :]\n",
    "    test = vals[n_train_day:, :]\n",
    "\n",
    "#------split into input and outputs\n",
    "    n_obs = n_days * n_features\n",
    "    train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "    test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "\n",
    "#------reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], n_days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], n_days, n_features))\n",
    "\n",
    "    model2 = Sequential()\n",
    "    model2.add(LSTM(unit, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model2.add(Dropout(drop_rate))\n",
    "    model2.add(Dense(1))\n",
    "    model2.compile(loss = loss_func[loss_select], optimizer='adam')\n",
    "    model2.summary()\n",
    "\n",
    "    history = model2.fit(train_X, train_y, epochs=times, batch_size=group_size, validation_data=(test_X, test_y), verbose=train_record, shuffle=shuff)\n",
    "\n",
    "#------make prediction\n",
    "    yhat = model2.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], n_days*n_features))\n",
    "\n",
    "#------invert scaling for forecast\n",
    "    inv_yhat = np.concatenate((yhat, test_X[:, -(n_features-1):]), axis=1)\n",
    "    inv_yhat = sc.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "\n",
    "#------invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = np.concatenate((test_y, test_X[:, -(n_features-1):]), axis=1)\n",
    "    inv_y = sc.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:show plots\n",
    "if show_history_plot:\n",
    "    fig=plt.figure(figsize=(20,8))\n",
    "    plt.xticks(rotation = 90)  \n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.plot(data.收盤價,color='red',label='收盤價')\n",
    "    ax1.plot(data.開盤價,color='green',label='開盤價')\n",
    "    plt.legend()\n",
    "    ax2 = ax1.twinx() #twinx = share x-axis\n",
    "    plt.bar(data.日期,data.當日成交量.astype('int')//1000)\n",
    "    ax3 = ax1.twinx()\n",
    "    if save_history_plot:\n",
    "        plt.savefig(symbol+'_year.png')\n",
    "if show_LSTM_config:\n",
    "    display(model.summary())\n",
    "if show_loss_plot:\n",
    "    plt.title('train_loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot( history.history[\"loss\"])\n",
    "    if multi:\n",
    "        plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.show()\n",
    "if show_prediction:\n",
    "    if not multi:\n",
    "        plt.plot(test[TARGET].values, color = 'black', label = 'Real stock data')\n",
    "        plt.plot(predicted_stock_price, color = 'green', label = 'Predicted Stock data')\n",
    "        plt.title('Stock Price Prediction')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('TARGET')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(\"TARGET = \"+TARGET)\n",
    "    else:\n",
    "        plt.plot(inv_y, color = 'black', label = 'Real Stock Price ')\n",
    "        plt.plot(inv_yhat, color = 'green', label = 'Predicted Stock Price')\n",
    "        plt.title('Stock Price Prediction')\n",
    "        plt.xlabel('Time')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    if save_prediction:\n",
    "        plt.savefig('lstm_2330.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag:Evaluation report\n",
    "print(\"Score:\")\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('RMSE: %.3f' % rmse)\n",
    "\n",
    "evs = explained_variance_score(inv_y, inv_yhat)\n",
    "print('EVS : %.3f' % evs)\n",
    "\n",
    "r2=r2_score(inv_y,inv_yhat)\n",
    "print('r2: %.3f' % r2)\n",
    "print()\n",
    "real,predict=confusion_matrix_list(inv_y,inv_yhat)\n",
    "matrix=confusion_matrix(real,predict,labels=[1,0,2])\n",
    "print(\"confusion matrix:\\n\",matrix,'\\n')\n",
    "\n",
    "report=classification_report(real,predict,labels=[1,0,2])\n",
    "print(\"Report:\\n\",report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
